<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Kaixuan Ji - Academic Homepage</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <div class="container">
        <div class="header-left">
            <img src="profile.png" alt="Kaixuan Ji" class="avatar">
        </div>
        <div class="header-center">
            <h1>Kaixuan Ji</h1>
            <p>Ph.D. Student in Computer Science, University of California, Los Angeles</p>
            <p>
                <a href="https://scholar.google.com/citations?user=example" target="_blank", style="color: antiquewhite;">Google Scholar</a> |
                <a href="mailto:kaixuanji@sc.ucla.edu" target="_blank", style="color: antiquewhite;">Email</a>
                <!-- Email: <a href="mailto:kaixuanji@cs.ucla.edu> -->
            </p>
        </div>
    </div>
</header>

<nav>
  <a href="index.html">About</a>
  <a href="publication.html">Publications</a>
  <a href="Resume_Kaixuan_Ji.pdf">Resume</a>
  <a href="misc.html">Miscellaneous</a>
</nav>


<section id="publications">
  <h2>Publications</h2>

  <h4>2025</h4>
  <ol>
    <li> <p> <a href="https://arxiv.org/abs/2402.09401">Reinforcement Learning from Human Feedback with Active Queries</a> 
        <br> Kaixuan Ji*, Jiafan He*, Quanquan Gu, <i>TMLR</i> 2025, <font color="red">Featured Certification</font> </p>
    </li>
    <li> <p> <a href="https://arxiv.org/abs/2405.00675">Self-play Preference Optimization for Language Model Alignment</a> 
        <br>Yue Wu*, Zhiqing Sun*, Huizhuo Yuan*, Kaixuan Ji, Yiming Yang, Quanquan Gu, <i>ICLR</i> 2025, </p>
    </li>
  </ol>

  <h4>2024</h4>
    <ol>
        <li> <p> <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/860c1c657deafe09f64c013c2888bd7b-Abstract-Conference.html">Self-play Fine-tuning of Diffusion Models for Text-to-image Generation</a> 
            <br> Huizhuo Yuan*, Zixiang Chen*, Kaixuan Ji*, Quanquan Gu, <i>NeurIPS</i> 2024</p>
        </li>
        <li> <p> <a href="https://arxiv.org/abs/2402.09401">Self-play Fine-tuning Converts Weak Language Models to Strong Language Models</a> 
            <br>Zixiang Chen*, Yihe Deng*, Huizhuo Yuan*, Kaixuan Ji, Quanquan Gu, <i>ICML</i> 2024</p>
        </li>
        <li> <p> <a href="https://arxiv.org/abs/2305.08359">Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs</a> 
            <br> Kaixuan Ji*, Qingyue Zhao*, Jiafan He, Weitong Zhang, Quanquan Gu, <i>ICLR</i> 2024 </p>
        </li>
    </ol>

    <h4>Before 2023</h4>
    <ol>
        <li> <p> <a href="https://arxiv.org/abs/2207.07087">Parameter-efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers</a> 
            <br>Weng Lam Tam*, Xiao Liu*, Kaixuan Ji, Lilong Xue, Xingjian Zhang, Yuxiao Dong, Jiahua Liu, Maodi Hu, Jie Tang, <i>Findings of EMNLP</i> 2023 </p>
        </li>
        <li> <p> <a href="https://aclanthology.org/2022.acl-short.8/">P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks</a> 
            <br>Xiao Liu*, Kaixuan Ji*, Yicheng Fu*, Weng Tam, Zhengxiao Du, Zhilin Yang, Jie Tang, <i>ACL</i> 2022 </p>
        </li>
    </ol>
    
</section>

<section id="preprints">
  <h2>Preprints</h2>
  <ol bottom-margin="2px">
    <li> <p> <a href="https://arxiv.org/abs/2310.10590">Mastering the Task of Open Information Extraction with Large Language Models and Consistent Reasoning Environment</a> 
        <br>Ji Qi*, Kaixuan Ji*, Xiaozhi Wang, Jifan Yu, Kaisheng Zeng, Lei Hou, Juanzi Li, Bin Xu, <i>arXiv:2310.10590</i></p>
    </li>
    <li> <p> <a href="https://arxiv.org/abs/2410.09302">Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization</a> 
        <br> Kaixuan Ji*, Guanlin Liu*, Ning Dai, Qingping Yang, Renjie Zheng, Zheng Wu, Chen Dun, Quanquan Gu, Lin Yan, <i>arXiv:2410.09302</i> </p>
    </li>
    <li> <p> <a href="https://arxiv.org/abs/2502.06051v2">Towards a Sharp Analysis of Offline Policy Learning for f-Divergence-Regularized Contextual Bandits</a> 
        <br> Qingyue Zhao*, Kaixuan Ji*, Heyang Zhao*, Tong Zhang, Quanquan Gu, <i>arXiv:2502.06051</i>. </p>
    </li>
  </ol>
</section>

<footer>
  &copy; 2025 Kaixuan Ji. All rights reserved.
</footer>

</body>
</html>
